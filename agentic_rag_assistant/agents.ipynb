{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb765985-1236-4026-8c29-b353862b7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04962940-f88a-462b-88a9-a9d41209eb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f22d0484-8081-40de-979c-a1e510ff6a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x76fd10c7a270>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615ef9e3-60d1-4f5b-a0d1-38fa7d6ef787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93903570-39ee-4d1e-a2d9-14feea7bc60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d48d435-ccad-405d-bd17-1e1c4c7fbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52fb7eee-300e-456b-a274-b29050b7d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results =  search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2998e835-3674-4411-beb8-8b19df355035",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe583e9-8cb7-4244-8885-4a73c9a32c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a ‚Äúlive‚Äù cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  ‚ÄúOffice Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don‚Äôt forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9092f0ac-ae08-4a6e-8424-a50fa86f8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "       model='gpt-3.5-turbo',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58947a08-dc84-4b92-8097-b5ed9cff3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee40dbb-1aae-45f7-90c0-202eefc5a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, you can still join the course even after the start date. However, it is important to note that there will be deadlines for turning in the final projects, so it is advised not to leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73fe5320-cac6-4c21-85b2-83f80490e073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka in Docker, you need to make sure that your Kafka broker docker container is working. Use the command `docker ps` to confirm its status. Then go to the docker compose yaml file folder and run `docker-compose up -d` to start all the instances.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('How do i run Kafka in Docker?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a43e2d-99db-41b4-9f47-bbfcd8bf3e85",
   "metadata": {},
   "source": [
    "### üß† Agentic RAG: Context & Decision Flow\n",
    "\n",
    "In a **Retrieval-Augmented Generation (RAG)** system, we enhance an LLM‚Äôs answers by adding external **context** (e.g., from FAQs).\n",
    "\n",
    "In **Agentic RAG**, the model:\n",
    "\n",
    "- üß† Decides when it needs more context  \n",
    "- üîç Chooses whether to **search the FAQ** or use **its own knowledge**  \n",
    "- üîÅ May chain actions: `SEARCH ‚Üí BUILD CONTEXT ‚Üí ANSWER`\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Agentic Decision Flow\n",
    "\n",
    "User Question\n",
    "‚Üì\n",
    "Is context available?\n",
    "‚Üì\n",
    "[Empty] ‚Üí Action = ‚ÄúSEARCH‚Äù\n",
    "‚Üì\n",
    "Retrieve FAQ results ‚Üí Build Context\n",
    "‚Üì\n",
    "Prompt LLM with Context\n",
    "‚Üì\n",
    "Action = ‚ÄúANSWER‚Äù ‚Üí Return Final Answer\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ What is Context?\n",
    "\n",
    "The **context** is a formatted block created from the retrieved FAQ entries:\n",
    "\n",
    "section: Getting Started\n",
    "question: How do I enroll?\n",
    "answer: Use the registration link before the course starts.\n",
    "\n",
    "section: Slack Access\n",
    "question: How do I join Slack?\n",
    "answer: Use the invite link shared in the onboarding email.\n",
    "\n",
    "This context is passed into the LLM prompt to help it **answer accurately using only verified sources**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "334afa38-1394-4c40-b62c-998b84180f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8e754bc-28b8-497c-a0cf-2f0de3480f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"Since the context is empty, I will search our FAQ database for information on running Docker on Gentoo.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I run docker on gentoo?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)\n",
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1b5f752-ae47-4c73-9c7d-bafbd37c4699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"Since the CONTEXT is empty, I will search our FAQ database to find a relevant answer on running Docker on Gentoo.\"\n",
      "}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "841f79dc-7fbd-493c-a10f-4732f88f6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"Since the CONTEXT is empty, I will search our FAQ database to find the answer to the student's question on how to join the course.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"how do I join the course?\"\n",
    "context = \"EMPTY\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a6d3d6a-83c4-46c8-ab74-10564647aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e7285c5-22ee-4b45-8bd7-eab739693d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QUESTION>\n",
      "how do I run docker on gentoo?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"Since the context is empty, I will search our FAQ database for information on running Docker on Gentoo.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c47980fc-0510-4fe2-b787-0c15e9e9c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json(text):\n",
    "    \"\"\"Extracts the first JSON block from a string.\"\"\"\n",
    "    match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        raise ValueError(\"No JSON found in LLM output.\")\n",
    "\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "    print(\"üß† Asking LLM (no context)...\")\n",
    "    raw_output = llm(prompt)\n",
    "    print(\"üîµ LLM response (1st):\")\n",
    "    print(raw_output)\n",
    "\n",
    "    try:\n",
    "        answer = json.loads(extract_json(raw_output))\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå JSON decode failed:\", e)\n",
    "        return raw_output\n",
    "\n",
    "    if answer[\"action\"] == \"SEARCH\":\n",
    "        print(\"üü° Searching FAQ...\")\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "\n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "        print(\"üß† Asking LLM (with context)...\")\n",
    "        raw_output = llm(prompt)\n",
    "        print(\"üîµ LLM response (2nd):\")\n",
    "        print(raw_output)\n",
    "\n",
    "        try:\n",
    "            answer = json.loads(extract_json(raw_output))\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå JSON decode failed (2nd call):\", e)\n",
    "            return raw_output\n",
    "\n",
    "    print(\"‚úÖ Final Answer:\")\n",
    "    print(answer[\"answer\"])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d750cdd-3e3d-4906-a2e7-79cc7136b2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Asking LLM (no context)...\n",
      "üîµ LLM response (1st):\n",
      "<QUESTION>\n",
      "how do I join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"Since the context is empty, I will use our FAQ database to find the answer.\"\n",
      "}\n",
      "üü° Searching FAQ...\n",
      "üß† Asking LLM (with context)...\n",
      "üîµ LLM response (2nd):\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To join the course, you need to register before the course starts using the provided registration link. Additionally, you should subscribe to the course public Google Calendar, join the course Telegram channel for announcements, and register in DataTalks.Club's Slack and join the channel.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "‚úÖ Final Answer:\n",
      "To join the course, you need to register before the course starts using the provided registration link. Additionally, you should subscribe to the course public Google Calendar, join the course Telegram channel for announcements, and register in DataTalks.Club's Slack and join the channel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To join the course, you need to register before the course starts using the provided registration link. Additionally, you should subscribe to the course public Google Calendar, join the course Telegram channel for announcements, and register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'source': 'CONTEXT'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "agentic_rag_v1('how do I join the course?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d014b8-11e7-4ed0-b35a-280230cb6361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
