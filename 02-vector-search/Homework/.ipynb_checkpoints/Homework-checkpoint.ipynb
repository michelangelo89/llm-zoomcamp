{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a207d145-ac1d-4a31-8e2e-a34696e0ea43",
   "metadata": {},
   "source": [
    "## Q1. Embedding the query  \n",
    "- **Answer:** `-0.11`  \n",
    "\n",
    "## Q2. Cosine similarity with another vector  \n",
    "- **Answer:** `0.90`  \n",
    "\n",
    "## Q3. Ranking by cosine  \n",
    "- **Answer:** `1`  \n",
    "\n",
    "## Q4. Ranking by cosine, version two  \n",
    "- **Answer:** `0`  \n",
    "\n",
    "In Q4, the highest scoring document changed from index 1 to index 0.  \n",
    "This is because concatenating the question with the text provided more context,  \n",
    "and the question of document 0 closely matched the query’s meaning.  \n",
    "The richer embedding led to a better semantic match.  \n",
    "\n",
    "## Q5. Selecting the embedding model  \n",
    "- **Answer:** `384`  \n",
    "\n",
    "## Q6. Indexing with qdrant (2 points)  \n",
    "- **Answer:** `0.87`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44956ea-de4f-4fc2-a5c4-33f55c8bcf4f",
   "metadata": {},
   "source": [
    "## Q1. Embedding the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5fe85ba-dc02-4a2f-af9e-81764a9505ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding: (512,)\n",
      "Minimal value in the embedding: -0.11726373885183883\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Create the embedder\n",
    "embedder = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Your query\n",
    "q = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "# Compute the embedding (returns a generator)\n",
    "embedding = next(embedder.embed([q]))\n",
    "\n",
    "# Confirm shape\n",
    "print(f\"Shape of embedding: {embedding.shape}\")\n",
    "\n",
    "# Find minimal value\n",
    "min_value = np.min(embedding)\n",
    "print(f\"Minimal value in the embedding: {min_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de95fd6-fab2-4c0a-9269-31cb3b833035",
   "metadata": {},
   "source": [
    "### Cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f83d4f1-2220-4326-93f3-72eb02659833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab5a194-ee2e-4b1c-b028-b7a76148bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all elements: -0.3649978092789794\n",
      "Norm of embedding: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum of all elements\n",
    "sum_of_elements = np.sum(embedding)\n",
    "print(f\"Sum of all elements: {sum_of_elements}\")\n",
    "\n",
    "# Norm (length of vector)\n",
    "norm = np.linalg.norm(embedding)\n",
    "print(f\"Norm of embedding: {norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e22a92-428a-4ee8-80da-99697cfad2f2",
   "metadata": {},
   "source": [
    "## Q2. Cosine similarity with another vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af830cb2-cdfa-45a7-930a-a1d6136446cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9008528895674548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your query and doc\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "doc = \"Can I still join the course after the start date?\"\n",
    "\n",
    "# Compute embeddings\n",
    "query_vec = next(embedder.embed([query]))\n",
    "doc_vec = next(embedder.embed([doc]))\n",
    "\n",
    "# Cosine similarity (dot product since both are normalized)\n",
    "cosine_sim = query_vec.dot(doc_vec)\n",
    "\n",
    "print(f\"Cosine similarity: {cosine_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9505a3-f3f7-4cb2-aed6-56a1c858a0db",
   "metadata": {},
   "source": [
    "## Q3. Ranking by cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea10e3a9-76f5-4eb0-94b2-b170fb656d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity scores: [0.76296845 0.81823782 0.80853974 0.71330788 0.73044992]\n",
      "Best document index: 1\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Instantiate embedder\n",
    "embedder = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Your query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "# Compute query embedding\n",
    "query_vec = next(embedder.embed([query]))\n",
    "\n",
    "# List of documents\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - Can I still join the course after the start date?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    \n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - Can I follow the course after it finishes?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    \n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - When will the course start?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    \n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - What can I do before the course starts?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    \n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'How can we contribute to the course?',\n",
    "     'course': 'data-engineering-zoomcamp'}\n",
    "]\n",
    "\n",
    "# Compute embeddings for the text field\n",
    "text_list = [doc['text'] for doc in documents]\n",
    "text_embeddings = list(embedder.embed(text_list))\n",
    "\n",
    "# Convert to matrix\n",
    "V = np.vstack(text_embeddings)\n",
    "\n",
    "# Compute cosine similarity\n",
    "scores = V.dot(query_vec)\n",
    "\n",
    "# Find the index with highest similarity\n",
    "best_idx = np.argmax(scores)\n",
    "\n",
    "print(f\"Cosine similarity scores: {scores}\")\n",
    "print(f\"Best document index: {best_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840108a-8fe9-456a-8a3c-a5d3d2d935f7",
   "metadata": {},
   "source": [
    "## Q4. Ranking by cosine, version two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f301d25b-f6d7-4147-8cc0-1fab7d98801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity scores (question + text): [0.85145432 0.8436594  0.84082872 0.77551577 0.80860079]\n",
      "Best document index (question + text): 0\n"
     ]
    }
   ],
   "source": [
    "# Build the new full_text field: question + text\n",
    "full_text_list = [\n",
    "    doc['question'] + ' ' + doc['text'] \n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Embed the combined question + text for each document\n",
    "full_text_embeddings = list(embedder.embed(full_text_list))\n",
    "\n",
    "# Convert to matrix\n",
    "V_full = np.vstack(full_text_embeddings)\n",
    "\n",
    "# Compute cosine similarities with the query vector\n",
    "scores_full = V_full.dot(query_vec)\n",
    "\n",
    "# Find the index with the highest similarity\n",
    "best_idx_full = np.argmax(scores_full)\n",
    "\n",
    "print(f\"Cosine similarity scores (question + text): {scores_full}\")\n",
    "print(f\"Best document index (question + text): {best_idx_full}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600eb03-8e31-4541-8859-ab3be54d1a47",
   "metadata": {},
   "source": [
    "## Q5. Selecting the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e02c283a-1f8a-41f7-b2e9-13b95ae0f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BAAI/bge-base-en, dim: 768\n",
      "Model: BAAI/bge-base-en-v1.5, dim: 768\n",
      "Model: BAAI/bge-large-en-v1.5, dim: 1024\n",
      "Model: BAAI/bge-small-en, dim: 384\n",
      "Model: BAAI/bge-small-en-v1.5, dim: 384\n",
      "Model: BAAI/bge-small-zh-v1.5, dim: 512\n",
      "Model: mixedbread-ai/mxbai-embed-large-v1, dim: 1024\n",
      "Model: snowflake/snowflake-arctic-embed-xs, dim: 384\n",
      "Model: snowflake/snowflake-arctic-embed-s, dim: 384\n",
      "Model: snowflake/snowflake-arctic-embed-m, dim: 768\n",
      "Model: snowflake/snowflake-arctic-embed-m-long, dim: 768\n",
      "Model: snowflake/snowflake-arctic-embed-l, dim: 1024\n",
      "Model: jinaai/jina-clip-v1, dim: 768\n",
      "Model: Qdrant/clip-ViT-B-32-text, dim: 512\n",
      "Model: sentence-transformers/all-MiniLM-L6-v2, dim: 384\n",
      "Model: jinaai/jina-embeddings-v2-base-en, dim: 768\n",
      "Model: jinaai/jina-embeddings-v2-small-en, dim: 512\n",
      "Model: jinaai/jina-embeddings-v2-base-de, dim: 768\n",
      "Model: jinaai/jina-embeddings-v2-base-code, dim: 768\n",
      "Model: jinaai/jina-embeddings-v2-base-zh, dim: 768\n",
      "Model: jinaai/jina-embeddings-v2-base-es, dim: 768\n",
      "Model: thenlper/gte-base, dim: 768\n",
      "Model: thenlper/gte-large, dim: 1024\n",
      "Model: nomic-ai/nomic-embed-text-v1.5, dim: 768\n",
      "Model: nomic-ai/nomic-embed-text-v1.5-Q, dim: 768\n",
      "Model: nomic-ai/nomic-embed-text-v1, dim: 768\n",
      "Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2, dim: 384\n",
      "Model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2, dim: 768\n",
      "Model: intfloat/multilingual-e5-large, dim: 1024\n",
      "Model: jinaai/jina-embeddings-v3, dim: 1024\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "# List supported models\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    print(f\"Model: {model['model']}, dim: {model['dim']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d09d02-e029-4fd7-941f-0d561bd0c9f9",
   "metadata": {},
   "source": [
    "## Q6. Indexing with qdrant (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7584ae-619d-4587-8e16-8e907600e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1a8ad94-81ee-4b01-a29b-5197b64cac05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 375 points successfully!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "import uuid\n",
    "\n",
    "# Connect to Qdrant\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Create collection (if not already created)\n",
    "client.create_collection(\n",
    "    collection_name=\"ml-zoomcamp-faq\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=384,  # embedding size for BAAI/bge-small-en\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Initialize embedder\n",
    "embedder = TextEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "# Prepare points\n",
    "points = []\n",
    "for doc in documents:\n",
    "    # Concatenate question + text\n",
    "    text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "    \n",
    "    # Embed the text\n",
    "    vector = next(embedder.embed([text]))\n",
    "    \n",
    "    # Create point with unique ID, vector, and payload\n",
    "    points.append(\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector=vector,\n",
    "            payload=doc\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Upsert points into Qdrant collection\n",
    "client.upsert(\n",
    "    collection_name=\"ml-zoomcamp-faq\",\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Upserted {len(points)} points successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccff14bc-b577-4e7e-9de6-825dec62c091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest score: 0.87031734\n",
      "Top match payload: {'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'section': 'General course-related questions', 'question': 'The course has already started. Can I still join it?', 'course': 'machine-learning-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "\n",
    "results = client.query_points(\n",
    "    collection_name=\"ml-zoomcamp-faq\",\n",
    "    query=models.Document(\n",
    "        text=query,\n",
    "        model=\"BAAI/bge-small-en\"\n",
    "    ),\n",
    "    limit=1,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"Highest score: {results.points[0].score}\")\n",
    "print(f\"Top match payload: {results.points[0].payload}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
